{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Đọc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "folder_paths = {\n",
    "    'data/raw/fake': 'Fake',\n",
    "    'data/raw/real': 'Real'\n",
    "    }\n",
    "\n",
    "dfs = [] \n",
    "\n",
    "for relative_path, label in folder_paths.items():\n",
    "    folder_path = os.path.join(os.getcwd(), relative_path)  # Path to folder\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]  # Filter json file\n",
    "\n",
    "    for file in json_files:\n",
    "        file_path = os.path.join(folder_path, file)  # Path to json\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:  # Read json\n",
    "                data = json.load(f)\n",
    "\n",
    "            if isinstance(data, dict):  # Convert a json dictionary to a list\n",
    "                data = [data]\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "            if df.shape[0] == 0:  # Check if the data file is empty\n",
    "                print(f\"File {file} don't have data.\")\n",
    "                continue\n",
    "\n",
    "            # Extract ID from the name of file (Fake_68, Real_15, ...)\n",
    "            file_parts = file.split(\"_\")  \n",
    "            file_id = \"_\".join(file_parts[-2:]).replace(\".json\", \"\")  \n",
    "            \n",
    "            # Unify maintext and text into maintext, if a maintext is missing, replace it with an empty space\n",
    "            if \"text\" in df.columns:\n",
    "                df.rename(columns={\"text\": \"maintext\"}, inplace=True)\n",
    "            if \"maintext\" not in df.columns:  \n",
    "                df[\"maintext\"] = \"\"  \n",
    "\n",
    "            # Handle authors, if a name is missing, replace it with an empty space\n",
    "            if \"authors\" in df.columns:\n",
    "                df[\"authors\"] = df[\"authors\"].apply(lambda x: \", \".join(x) if isinstance(x, list) and len(x) > 0 else \"\")\n",
    "\n",
    "            # Add id and target (Fake/Real) to the dataframe\n",
    "            df['id'] = file_id  \n",
    "            df['target'] = label  \n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error when reading file {file}: {e}\")\n",
    "\n",
    "# Concat all the dataframes \n",
    "df = pd.concat(dfs, ignore_index=True, join='outer')\n",
    "df = df.fillna('')\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'authors', 'source_domain', 'language', 'title', 'description', 'maintext', 'target']]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature `Language` has 3 values (vi, en, empty) in comparision with others, so it doesn't play any crucial role in the Decision tree (at section Rule-based systen) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df[df.duplicated(subset=df.columns.difference(['id']), keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=105, inplace=True)  # Drop the row with index 105\n",
    "df.reset_index(drop=True, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for imbalance. Fake and Real values are nearly equal, so no resampling is needed\n",
    "df['target'].value_counts()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tìm rule-based system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Decision Tree with entropy as the criterion\n",
    "def model_tree(depth):\n",
    "    model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42) \n",
    "    return model\n",
    "\n",
    "\n",
    "# Measure an accuracy for Decision tree\n",
    "def calculate_acc(dataframe, x_features, y_feature, model=model_tree):    \n",
    "    X = x_features \n",
    "    y = dataframe[y_feature].values\n",
    "\n",
    "    # Take 80% dataset for training, 20% for testing model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "\n",
    "    # Training model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate accuracy after training the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f\"Accuracy of Decision Tree: {accuracy:.2%}\"\n",
    "\n",
    "\n",
    "# Create a tree plot\n",
    "def plot_decision_tree(model, x_features):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_tree(model, feature_names=x_features, class_names=[\"Fake\", \"Real\"], filled=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tìm RB dựa trên `source_domain` và `authors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['authors', 'source_domain', 'target']]\n",
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode source_domain and authors using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder_source = LabelEncoder()\n",
    "encoder_authors = LabelEncoder()\n",
    "\n",
    "df1[\"source_domain_encoded\"] = encoder_source.fit_transform(df1[\"source_domain\"])\n",
    "df1[\"authors_encoded\"] = encoder_authors.fit_transform(df1[\"authors\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model1 = model_tree(depth=4)\n",
    "\n",
    "X_le = np.hstack([df1[\"source_domain_encoded\"].values.reshape(-1, 1),\n",
    "                  df1[\"authors_encoded\"].values.reshape(-1, 1)])\n",
    "\n",
    "print(calculate_acc(df1, X_le, 'target', model=tree_model1))\n",
    "print(plot_decision_tree(tree_model1, X_le))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping table for source_domain\n",
    "df_mapping_source = pd.DataFrame({\"source_domain_encoded\": df1[\"source_domain_encoded\"],\n",
    "                                  \"source_domain_original\": df[\"source_domain\"]}\n",
    "                                  ).drop_duplicates().sort_values(by=\"source_domain_encoded\", ascending=True)\n",
    "df_mapping_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping table for source_domain as a txt file\n",
    "with open(\"mapping_source.txt\", \"w\") as f:\n",
    "    f.write(df_mapping_source.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['source_domain'].str.contains('giadinhtiepthi.com', case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping table for authors\n",
    "df_mapping_authors = pd.DataFrame({\"authors_encoded\": df1[\"authors_encoded\"], \n",
    "                                   \"authors_original\": df[\"authors\"]}\n",
    "                                   ).drop_duplicates().sort_values(by=\"authors_encoded\", ascending=True)\n",
    "df_mapping_authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping table for authors as a txt file\n",
    "with open(\"mapping_authors.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(df_mapping_authors.to_string(index=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tìm RB dựa trên `title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['title', 'target']]\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load n-grams from a file\n",
    "def read_ngrams(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Read the n-gram list from three files\n",
    "dictionaries_path = os.path.join(os.getcwd(), \"dictionaries\")\n",
    "bi_grams = read_ngrams(os.path.join(dictionaries_path, \"bi_gram.txt\"))\n",
    "tri_grams = read_ngrams(os.path.join(dictionaries_path, \"tri_gram.txt\"))\n",
    "four_grams = read_ngrams(os.path.join(dictionaries_path, \"four_gram.txt\"))\n",
    "\n",
    "# Compile a list of all n-gram\n",
    "all_ngrams = set(bi_grams + tri_grams + four_grams)\n",
    "\n",
    "print(\"The number of n-grams:\", len(all_ngrams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Extract title data\n",
    "titles = df2[\"title\"].astype(str).tolist()\n",
    "\n",
    "# Initialize TfidfVectorizer with an n-grams list from the file\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 4), vocabulary=all_ngrams)\n",
    "\n",
    "# Calculate TF-IDF\n",
    "X_tfidf = vectorizer.fit_transform(titles)\n",
    "\n",
    "# Get the list of feature words\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = np.array(X_tfidf.mean(axis=0)).flatten()\n",
    "\n",
    "# Convert to DataFrame and sort TF-IDF weights in descending order\n",
    "df2_tfidf = pd.DataFrame({'N-gram': feature_names, 'TF-IDF Score': tfidf_scores}).sort_values(by=\"TF-IDF Score\", ascending=False)\n",
    "\n",
    "df2_tfidf.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 n-grams with the highest weights\n",
    "top_ngrams = df2_tfidf.nlargest(300, 'TF-IDF Score')[\"N-gram\"].tolist()\n",
    "\n",
    "\n",
    "# Create a feature matrix from df2['title']\n",
    "vectorizer_top = TfidfVectorizer(ngram_range=(2, 4), vocabulary=top_ngrams)\n",
    "# Vector the data\n",
    "X_tfidf_top = vectorizer_top.fit_transform(df2[\"title\"]).toarray()\n",
    "\n",
    "\n",
    "tree_model2 = model_tree(depth=50)\n",
    "print(calculate_acc(df2, X_tfidf_top, 'target', model=tree_model2))\n",
    "# print(plot_decision_tree(tree_model2, vectorizer_top.get_feature_names_out()))\n",
    "\n",
    "feature_names = vectorizer_top.get_feature_names_out().tolist()\n",
    "print(export_text(tree_model2, feature_names=feature_names))\n",
    "# print(export_text(tree_model2, feature_names=vectorizer_top.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tổng hợp rule-based system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math  \n",
    "\n",
    "def rule_based_classification(source, author, text_title):\n",
    "    # List of fake news sources\n",
    "    fake_sources = {\n",
    "        '2sao.vn', 'anninh247.xyz', 'autoxe.net', 'baoangiang.com.vn', 'baonuocmy.com', \n",
    "        'baophapluat.online', 'binhluan.biz', 'blogxcy.wordpress.com', 'cand.com.vn', 'congtintuc24gio.com',\n",
    "        'thoibao.de', 'thoibao.today', 'tingame.info', 'tintuconline.com.vn', 'tintucqpvn.net', \n",
    "        'tinvn.info', 'trumpandq.blogspot.com', 'tuvanannam.com', 'vietgiaitri.com', 'vinaexpress.com.vn'}\n",
    "\n",
    "    # List of suspicious authors\n",
    "    fake_author_keywords = {'An Bình', 'CÔNG TRUNG', 'Cùng Tác Giả', 'D.KIM THOA', 'Gioi Tre Viet',\n",
    "                            'Hiếu Công', 'Hoàng Vy Thế Giới Trẻ', 'Hạ Huyền', 'J', 'Daisy'}\n",
    "  \n",
    "    # Keywords and TF-IDF threshold: Above this means fake\n",
    "    keywords = {'sự thật': 0.17,\n",
    "                'con gái': 0.22,\n",
    "                'kinh dị': 0.25,\n",
    "                'tài xế': 0.24,\n",
    "                'bí mật': 0.25,\n",
    "                'đàn ông': 0.43,\n",
    "                'tất cả': 0.18,\n",
    "                'báo mộng': 0.25,\n",
    "                'lý do': 0.26,\n",
    "                'cải cách': 0.28,\n",
    "                'cảnh tượng': 0.20}\n",
    "    \n",
    "    # List of punctuation marks to check (excluding period . and comma ,)\n",
    "    punctuation_to_check = set(string.punctuation) - {'.', ','}\n",
    "    \n",
    "    # Rule 1: Determine the Fake ratio based on source and author\n",
    "    fake_source = source in fake_sources\n",
    "    fake_author = any(keyword in author for keyword in fake_author_keywords) \n",
    "\n",
    "    if fake_source and fake_author:\n",
    "        fake_score_source_author = 1 * 0.9  # Fake both source and author\n",
    "    elif fake_source or fake_author:\n",
    "        fake_score_source_author = 0.5 * 0.9  # Fake just source or author\n",
    "    else:\n",
    "        fake_score_source_author = 0  # No Fake in both\n",
    "    \n",
    "    # Rule 2: Calculate TF-IDF to check keywords\n",
    "    vectorizer = TfidfVectorizer(vocabulary=keywords.keys()) \n",
    "    tfidf_matrix = vectorizer.fit_transform([text_title])\n",
    "    \n",
    "    fake_score_keywords = 0\n",
    "    count_violations = 0\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for idx, word in enumerate(feature_names):\n",
    "        if tfidf_matrix[0, idx] > keywords[word]:  \n",
    "            count_violations += 1  \n",
    "\n",
    "    # Check punctuation directly in text_title\n",
    "    count_punctuation_violations = sum(1 for p in punctuation_to_check if p in text_title)\n",
    "    count_violations += count_punctuation_violations \n",
    "    \n",
    "    # Calculate the Fake score based on the number of violations\n",
    "    if count_violations > 0:\n",
    "        fake_score_keywords = 1 - math.pow(0.75, count_violations) \n",
    "    \n",
    "    # Calculate the Fake/Real ratio from source/author and keywords\n",
    "    fake_score = fake_score_source_author + fake_score_keywords\n",
    "    real_score = 1 - fake_score\n",
    "\n",
    "    return {'fake_score':round(fake_score, 2), 'real_score': round(real_score, 2) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-test with an example \n",
    "source = 'thoibao.today'\n",
    "author = ''\n",
    "text_title = 'Khám phá sửng sốt về trí nhớ \\\"như thần\\\" của động vật' \n",
    "\n",
    "result = rule_based_classification(source, author, text_title)\n",
    "result\n",
    "# result['fake_score']  # Chỉ in Fake_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fine-tune LLM \n",
    "\n",
    "Dùng Pho-BERT để huấn luyện bộ tin tức Tiếng Việt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = \"vinai/phobert-base-v2\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "bert = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Tạo ngẫu nhiên giá trị cho cột fake_score trong df\n",
    "\n",
    "Cho tin tức có target là 'Real', thì sẽ được gán giá trị fake_score từ trong khoảng từ 0 - 0.1. Còn 'Fake' thì là từ 0.11 đến 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fake_score(target):\n",
    "    if target == \"Fake\":\n",
    "        return np.random.uniform(0.11, 1.0)\n",
    "    else:\n",
    "        return np.random.uniform(0.0, 0.1)\n",
    "\n",
    "# Apply function to create fake_score column\n",
    "df[\"fake_score\"] = df[\"target\"].apply(assign_fake_score)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Chia dataset ra tập train, validation và test\n",
    "\n",
    "Chia tập dataset Train-Validation-Test theo ratio 70:15:15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['maintext'], df['fake_score'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3)\n",
    "# Validation-Test split\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(test_texts, test_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 218\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_texts.tolist(),\n",
    "    max_length = MAX_LENGTH,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_texts.tolist(),\n",
    "    max_length = MAX_LENGTH,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_texts.tolist(),\n",
    "    max_length = MAX_LENGTH,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Convert lists to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "\n",
    "train_labels = torch.tensor(train_labels.tolist()) # Convert to flat tensor\n",
    "val_labels = torch.tensor(val_labels.tolist())\n",
    "test_labels = torch.tensor(test_labels.tolist())\n",
    "\n",
    "train_y = train_y.view(-1, 1)  # Reshape labels to (num_samples, 1)\n",
    "val_y = val_y.view(-1, 1)\n",
    "test_y = test_y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Dựng Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader structure definition\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32                                               #define a batch size\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n",
    "train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for train set\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n",
    "val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for validation set\n",
    "\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)    # wrap tensors\n",
    "test_sampler = SequentialSampler(test_data)                     # sampler for sampling the data during training\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Dựng model\n",
    "\n",
    "Đảm bảo là gradient vẫn sẽ được tính qua các layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Define the PhoBERT-based regression model\n",
    "class PhoBERTRegressor(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(PhoBERTRegressor, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.sigmoid = nn.Sigmoid()  # Ensures output is between 0 and 1\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Use logits directly\n",
    "        return self.sigmoid(logits)  # Apply sigmoid for output in (0,1)\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model and move it to the appropriate device\n",
    "model = PhoBERTRegressor(bert).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # Learning rate\n",
    "loss_fn = nn.MSELoss().to(device)  # Mean Squared Error for regression tasks\n",
    "\n",
    "# Set number of training epochs\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Dựng training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):  \n",
    "        # Progress update every 50 batches\n",
    "        if step % 50 == 0 and step != 0:\n",
    "            print(f'  Batch {step:,} of {len(train_dataloader):,}.')\n",
    "\n",
    "        # Move batch data to device\n",
    "        sent_id, mask, scores = [t.to(device) for t in batch]\n",
    "        scores = scores.float()  # Ensure labels are float for regression\n",
    "\n",
    "        # Clear previous gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(input_ids=sent_id, attention_mask=mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, scores)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Prevent exploding gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for step, batch in enumerate(val_dataloader):\n",
    "            # Progress update every 50 batches\n",
    "            if step % 50 == 0 and step != 0:\n",
    "                print(f'  Batch {step:,} of {len(val_dataloader):,}.')\n",
    "\n",
    "            # Move batch data to device\n",
    "            sent_id, mask, scores = [t.to(device) for t in batch]\n",
    "            scores = scores.float()  # Ensure labels are float for regression\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(preds, scores)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Compute average validation loss\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Huấn luyện model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "train_losses=[]                   # empty lists to store training and validation loss of each epoch\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    train_loss = train()                       # train model\n",
    "    valid_loss = evaluate()                    # evaluate model\n",
    "    if valid_loss < best_valid_loss:              # save the best model\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model_weights.pt')\n",
    "    train_losses.append(train_loss)               # append training and validation loss\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Chạy bộ test data với model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_dataloader(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation needed\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, _ = batch  # Ignore labels (if present)\n",
    "            \n",
    "            # Move inputs to the same device as the model\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            scores = outputs.cpu().numpy().flatten()  # Convert to NumPy\n",
    "            \n",
    "            predictions.extend(scores)  # Store results\n",
    "\n",
    "    return predictions  # Returns a list of predicted scores\n",
    "test_predictions = predict_from_dataloader(model, test_dataloader, device)\n",
    "\n",
    "# Create DataFrame\n",
    "test_df = pd.DataFrame({\"text\": test_texts, \"predicted_realness_score\": test_predictions})\n",
    "\n",
    "# Save results to CSV\n",
    "test_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Kết hợp Rule-based và LLM\n",
    "\n",
    "Kết hợp fake-score của Rule-based và của LLM để cho ra nhận định cuối là tin thật hay giả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
